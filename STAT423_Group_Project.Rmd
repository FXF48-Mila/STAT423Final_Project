---
title: "STAT423_Group_Project"
output: html_document
date: "2024-02-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(MASS)
library(caret)
library(faraway)
```

```{r}
data <- read.csv("Health_insurance.csv")
```

```{r}
head(data)
skimr::skim(data)
```

```{r}
# Encoding categorical data
data$sex <- as.numeric(as.factor(data$sex))
data$smoker <- as.numeric(as.factor(data$smoker))
data$region <- as.numeric(as.factor(data$region))
```

```{r}
par(mfrow=c(2,2))
hist(data$age, main="Age Distribution", xlab="Age")
hist(data$bmi, main="BMI Distribution", xlab="BMI")
hist(data$children, main="Children Distribution", xlab="Children")
hist(data$charges, main="Charges Distribution", xlab="Charges")
```
```{r}
data %>%
  group_by(children) %>%
  count()
```

```{r}
fit1 <- lm(charges ~ ., data = data)
summary(fit1)
```

```{r}
# Log transformation
# data$charges <- log(data$charges)

# Box-Cox transformation
bc_transform <- boxcox(charges ~ ., data = data, lambda = seq(-2, 2, by=0.1))
title(main = "95% CI for the Box-Cox transform.")
```

From the box-cox transformation, $\lambda=1$ does not include in 95% confidence interval, so the box-cox transformation is necessary.


```{r}
data$charges <- log(data$charges)
```


```{r}
pairs(data)
correlation_matrix <- cor(data[c("age", "sex", "bmi", "children", "smoker", "region", "charges")])
correlation_matrix
```

```{r}
library(corrplot)
cor_matrix <- cor(data[-7])
corrplot(cor_matrix, method = "circle")
```


```{r}
# histogram of box-cox transformed charges
hist(data$charges)
```


```{r}
trainIndex <- createDataPartition(data$charges, p = .8, 
                                  list = FALSE, 
                                  times = 1)
trainData <- data[trainIndex, ]
testData <- data[-trainIndex, ]
```


```{r}
model <- lm(charges ~ ., data = data)
summary(model)
```

```{r}
hist(residuals(model), main="Histogram of Residuals", xlab="Residuals", breaks=30)
qqnorm(residuals(model))
qqline(residuals(model), col="red")
```
```{r}
par(mfrow=c(2, 2))
plot(model,which=1)
plot(model,which=2)
plot(model,which=3)
plot(model,which=4)
```
# Multicollinearity

```{r}
vif(model)
```
We can see that the standard error for all the parameters in the full model are all small. Thus, there should not be serious multicollinearity
problem for this model. Let's check the multicollinearity for each variable by calculating the vif.

According to the vif that we have calculated for the model, we can see that all of the vif are smaller than 5, meaning that there isn't serious multicollinearity for our parameters. 


# Research Question 3

```{r, echo = F}
fit_full <- lm(charges ~age*sex*bmi*children*smoker*region, data = data)
fit_resPre <- lm(charges ~age+sex+bmi+children+smoker+region, data = data)

summary(fit_resPre)
```

First considering the significance level of the personal information. The sex of the individual does not significantly affect medical insurance charges in this analysis. This implies that, within the scope of the variables considered, there is no discernible difference in charges between males and females. Regarding region, while the northwest region does not significantly differ from the northeast, the southeast and southwest regions exhibit lower charges on average compared to the northeast.

Additionally, we can see age, BMI, children, and smoking status are all have a p-value smaller than any significance level. These personal information all have significant effects on predicting insurance charges. To be more specific, age demonstrates a strong positive association with charges, with each one-year increase in age corresponding to an increase in charges of $\$256.9$, holding other predictors constant. Similarly, BMI also positively correlates with charges, with each one-unit increase resulting in an increase of $\$339.2$ in charges. Additionally, the number of children in a family positively influences charges, with each additional child contributing an increase of $\$475.5$ in health insurance charges. Smoking status serves as a significant predictor, with smokers facing substantially higher charges compared to non-smokers. The presence of a smoker in the family is associated with an average increase of $\$23848.5$ in charges. 

Besides all above personal information, the remaining factors such as sex and region are all have negative impact on the health insurance charges and these factors are all not insignificant.

In general, the model explains approximately 75.09\% of the variance in medical insurance charges, suggesting that the included predictors collectively offer valuable insights into the factors influencing health insurance charges. The model's statistical significance, as shown by the F-statistic (p-value < $2.2 \times 10^{-16}$), indicates that the regression model is highly statistically significant. In practical terms, this means that there is strong evidence to reject the null hypothesis. That is at least one regression coefficients are not equal to zero.


# changing children to a categorical variable

```{r}
data %>%
  group_by(children) %>%
  count()
```

```{r}
data <- data %>%
  mutate(children_category = ifelse(children > 0, "have child", "no child"))
data$children_category <- as.factor(data$children_category)
```

```{r}
fit <- lm(charges ~ age*sex*bmi*children_category*smoker*region, data = data)
summary(fit)
```
```{r}
par(mfrow=c(2, 2))
plot(fit,which=1)
plot(fit,which=2)
plot(fit,which=3)
plot(fit,which=4)
```
```{r}
par(mfrow=c(2,2))
plot(fit)
```

